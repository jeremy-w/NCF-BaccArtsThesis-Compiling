\section{Types}
When we mentioned types earlier, we took for granted that the meaning was clear enough based on shared experience of types in common programming languages. Now, we wish to discuss the functional languages. Here, we cannot rely on shared experience. Functional languages have seen some use as testbeds for practical applications of developments in type theory. Modern functional languages are founded not only on the \lambdacalc{}, but on typed \lambdacalcs{}. But the \lambdacalc is a poor way to introduce the terminology and concepts of types, and so we shall first discuss types in order to develop an intuitive understanding of some concepts that we will later introduce into the \lambdacalc{}. Before we go on to discuss the languages themselves, then, we would do well to look a bit more carefully at the concept of \asword{type.}

Types are introduced into programming languages in order to make the language safer and easier to compile efficiently. Types make the language safer by making it much easier for the compiler to catch nonsensical operations, such as trying to add a string to a pointer and store the result in a structure. If a language can guarantee that operations of one type will not be applied to operands of an incompatible type, then we say the language is \vocab{type safe}. In a type safe language, a type inconsistency becomes a critical error. Consequently, programs, especially large, complex programs, written in type-safe languages are easier to debug than those written in non--type-safe languages. Types can also make the language easer to compile efficiently. Different types of data can, or sometimes must, be dealt with in different ways at the machine level. Types increase the amount of knowledge about the elements of the program available to the compiler for optimization and allow the resulting code to be specialized to the types involved.

Providing type information, however, can be burdensome on the programmer. It is desirable that the programmer need not explicitly specify the types involved in the program, but rather that the types be implicit in the values used and behaviors specified. This is done through \vocab{type inference}. Once all types have been inferred, type checking can proceed; once the program successfully passes type checking, the type information can be used in optimization and code generation.

Now that we have clarified how types are used and why they matter, it is time to be clearer about what types are. Quite simply, we can look at a \vocab{type} as an identified set of values. These sets can overlap or be disjoint. The integer \code{6} falls into both the integer subranges \code{1..10} and \code{5..15}. But the set of all integers and the set of all strings is distinct; even the integer \code{5} and the string ``5'' containing the character \asword{5} can be made readily distinguishable by introducing the lexical convention of writing strings within quotation marks. Sets can also be related by inclusion. All integers and reals are also numbers at the same time. From this, we can see that a given value can belong to a set of types. To express that a given value is of a given type, we write \stmt[math]{\langle \text{\textit{value}} \rangle}{\langle \text{\textit{Type}} \rangle}.

We can also construct types from other types. With $\to$, we can build the type of functions from one type to another from the types of its domain and codomain. The integer successor function \code{succ}, defined such that $\text{\code{succ} } \stmt{x}{Int} = x + 1$, that is, it takes an integer as input and outputs that integer incremented by 1, would then have type \type{Int $\to$ Int}. \vocab{Product types} are tuples with the various components of the tuple capable of taking on values of various types. To represent a specific tuple, we write its elements as a comma-separated list within parentheses. For example, \code{(1, 'A')} is a specific tuple to which we could assign the type $\type{Int} \times \type{Char}$. If we allow the components of the tuple to be referenced by name rather than ordinal position, we find that we have reinvented structures (in the terminology of C) or records (in the terminology of Pascal).

The \vocab{type system} of a language is often specified in this way, by enumerating the \vocab{base types} and then describing how those types can be combined to form other types. In this way, the type system itself represents a small language of types with its own syntactic and lexical rules and its own semantic content embedded within the larger context of the programming language itself.

\subsection{Polymorphism}\label{types:polymorphism}
\subsubsection{Parametric and Ad Hoc}
\vocab[polymorphism]{Polymorphism} is the property of being of many types. It stands opposed to \vocab{monomorphism}, the property of being of a single type. Both concepts are broadly applicable to the typed elements of programming languages\empause variables, functions, operators, sometimes even modules\empause and, by extension, to programming languages themselves: a polymorphic language exhibits polymorphism wherever possible, an almost polymorphic language has fewer polymorphic features, a nearly monomorphic language has virtually none, and a monomorphic language has purely monomorphic features.

Traditionally, polymorphism is informally divided into two kinds based on the polymorphism exhibited by a function: \vocab{parametric polymorphism}, where the function behaves uniformly across all types, and \vocab{ad hoc polymorphism}, where the behavior of the function is specified separately for different types.

In parametric polymorphism, the parametric type of the function is best expressed by introducing a \vocab{type variable}. For example, if we use the notation $[\langle \text{\textit{type}} \rangle]$ to represent a list of the given type, then a generic length function parameterized on the type of the list would have type $\forall \alpha. [\alpha] \to \type{Int}$.\footnote{In fact, we can view the square bracket notation $[\type{T}\/]$ for a list of type \type{T} as a syntactic convenience for expressing the application of the parametric type constructor $\typecon{List} \alpha$ to the type \type{T}.} This expresses that \const{length} has type ``function from list of type $\alpha$ to \type{Int} for all types $\alpha$ ($\forall \alpha$).'' It is possible to define such a function because of the common structure of all types of lists. This is not unusual: parametric polymorphism is frequently achieved by exploiting some common property of the types involved.

Ad hoc polymorphism, on the other hand, requires separate definitions for all types involved. The addition operator \code{+} is frequently ad hoc polymorphic. When given two integers, it returns an integer; when given two real numbers, it returns a real number; in some languages, when given two strings, it returns their concatenation, so that \code{"to" + "day"} returns \code{"today"}. It is the nature of ad hoc polymorphism that the function will not be defined for all possible types and will not be uniformly defined even for those types to which it can be applied, as in the dual uses of \code{+} for both numerical addition and string concatenation.

It is, in fact, possible to regard ad hoc polymorphism as monomorphism together with the \vocab{overloading} of function names. From this point of view, \code{+} is not a single function applicable to two values both either integers, reals, or strings, but is in fact three different monomorphic functions that share a single name. By examining the types of the supplied arguments, the overloading can be resolved, so that, for example, \const{1 + 2} can be turned into a call to \code{addInt} and \code{1.0 + 2.0} to a call to \code{addReal}, while \code{"to" + "day"} can be turned into a call of \code{concatString}.

\begin{table}[btp]
\caption{Ad hoc polymorphism as overloading}
\myfloatalign
\begin{tabular}{cc}
\toprule
\tableheadline{Overloaded Call} &\tableheadline{Resolved To}\\
\midrule
\code{1 + 2} &\code{addInt 1 2}\\
\code{1.0 + 2.0} &\code{addReal 1 2}\\
\code{"to" + "day"} &\code{concatString "to" "day"}\\
\bottomrule
\end{tabular}
\end{table}

Matters become more confused when we introduce \vocab{coercion}, the implicit forcing of a value from one type into another. This is common with numeric arguments: if a function of type \type{Real}~$\to$~\type{Real} is applied to an \type{Int}, the \type{Int} value might be coerced to a value of type \type{Real}, so that \code{floor 4} becomes \code{floor (toReal 4)}, as if the programmer had written \code{floor 4.0}. With coercion and overloading in force, what happens when \code{1 + 2.0} is encountered? Would it be as if the programmer had instead written \code{addIntReal 1 2.0}, an addition function expecting an integer and a real as its two inputs, or would the integer be coerced so that \code{addReal} could be used? Does \code{addInt} even exist, or are integers always coerced to be of type \code{Real} before invoking \code{addReal}?\footnote{We owe this example to \citet[p.~476]{Cardelli:On-understanding:1985}.}

\subsubsection{Subtype}
\vocab[subtype polymorphism]{Subtype polymorphism} is a restricted kind of parametric polymorphism in which the universal quantification of the type variable is restricted to the universe of those types that are subtypes of some other type. For example, a parametrically polymorphic function for sorting lists relies on the fact that the type of the lists is ordered in some way. Thus, what is desired is to express that \code{sort} is a function from lists of some ordered type to lists of the same ordered type, which is to say that it is a function from lists of all types where the type is ordered to lists of the same type. If we introduce \code{Order} as the type of all ordered types and write $A \subseteq B$ to express that $A$ is a subtype of $B$, then we can assign \code{sort} the type $\forall \alpha \subseteq \type{Order} . [\alpha] \to [\alpha]$. This combination of universal quantification and subtyping is referred to as \vocab{bounded universal quantification}.
