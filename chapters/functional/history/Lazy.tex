\subsection{Lazy Languages}
Our description of modern eager languages focused on the prominent \abbrev{ML} family. Modern lazy languages developed a bit differently. Much of the early work in lazy languages was done by Turner in a series of languages developed during the late 1970s and early 1980s.

1976 saw the appearance of \abbrev{SASL}, the St. Andrews Static Language. It introduced the equational style of function definition and the use of guards. Functions were automatically curried, and indentation could be used in place of semicolons. The type system was rudimentary.

\abbrev{KRC}, the Kent Recursive Calculator, made its debut in 1981. It made lists easier to use by introducing a shorthand notation and list comprehensions. Both will seem quite familiar to anyone acquainted with higher mathematics. Shorthand notation allowed the use of ellipsis dots to express ranges. Thus, \code{[1..5]} is equivalent to \code{[1, 2, 3, 4, 5]}, and \code{[1..]} creates the infinite list \code{[1, 2, 3, 4..]}. \vocab{List comprehensions}\footnote{We now call them \asword{list comprehensions}. At the time, they were described as both \asword{set expressions} and \asword{ZF expressions.}} provide a compact notation for generating lists from other lists.

For example,
\begin{lstlisting}
[ 2*x | x <- [0..], 2*x < 100 ]
\end{lstlisting}
can be read as ``the list with elements $2 * x$, where $x = 0, 1, \dotsc$ and $2 * x < 100$.'' This is similar to the set expression $\set{x \where x \in \mathbb{N} \land 2\cdot x < 100}$. As you can see, the notation for the list comprehension has two sides. The right hand side contains generating expressions and filters. Generating expressions such as \lstinline{x <- [0..]} introduce a name. In the course of evaluating the list comprehension, this name will be bound to each value of the generating list in turn. The left arrow \lstinline{<-} can be read as ``drawn from.'' Filters evaluate to either true or false. If they all evaluate to true, then the current bindings of the names introduced by the generating expressions are used to evaluate the expression on the left hand side of the list comprehension. The result of evaluating the left hand side expression is appended to the output list, new bindings are made, and the process repeats. (While this description has not gone over all the details, it should be enough to communicate the flavor and expressiveness of list comprehensions.)

We likened list comprehensions to the set expressions used in mathematics, but a list comprehension differs from a mathematical set expression in two important ways:
\begin{itemize}
\item
It can contain duplicates.
\item
It is produced algorithmically and its results are ordered.
\end{itemize}
A simple list comprehension containing duplicates is \lstinline{[1 | x <- [1..3]]}, which produces \lstinline{[1, 1, 1]}. That the results are ordered is necessitated by our drawing values from lists and putting the results in a list. That the result is produced algorithmically is important when we use infinite lists, as above where \lstinline{x} is drawn from a list of natural numbers. Even though we know that, once the output list has had $98$ appended to it, no greater value of $x$ will satisfy the predicate $2\cdot x < 100$, the interpreter will continue to evaluate the list comprehension until as many values as we ask for have been produced; if we ask for all values, it will continue forever, since there is always one more $x$ to try in the infinite list \lstinline{[0..]}. Thus, thinking of these as set expressions rather than attractively concise ways to generate lists can lead to trouble.

Turner's language design efforts culminated in Miranda. Miranda was the first of his languages to feature a Hindley--Milner type system. It included user-defined types and polymorphism. It also featured \vocab[operator sections]{sections}, which solve a notational problem with infix operators. If we want to map a normal, prefix function \lstinline{f} down a list \lstinline{L}, then \lstinline{map f L} suffices. But if we wish to halve each element of the list, we must resort to either defining a throw-away function, say \lstinline{half x = x / 2}, or defining an anonymous function using lambda notation, such as \lstinline{\ x -> x / 2}. Sections make it possible to refer to use the infix operator directly here. Sections are written by surrounding the infix operator in parentheses. If the operator alone is in parentheses \lstinline{(/)}, it is called a section; if a value is supplied to the left or right, it is known as a left or right section, respectively. Thus, we could express ``halve each element'' by composing \lstinline{map} with a right section of \lstinline{/}: \lstinline{map (/2) L}. Likewise, we could generate a list of the reciprocals of all elements of the list \lstinline{L} using \lstinline{map} and a left section of \lstinline{/}: \lstinline{map (1/) L}.

Turner founded a company in 1983 to commercialize Miranda. He attempted to transfer lazy functional programming into industry. Miranda was the most developed lazy functional programming language of its time, but Miranda was not free. Distribution of derivatives was prohibited without the company's consent in order to avoid a proliferation of dialects and to keep Miranda programs portable, which led to some conflicts with other researchers.

The late 1970s and early 1980s had seen a proliferation of similar lazy, purely functional languages. The syntax differed, but the semantics were virtually identical, so that researchers had no problem understanding each other's papers. But the lack of a common language was seen as a problem for both research, through the duplication of effort, and for promoting use of lazy functional languages outside of research, since no single language was supported and most had been developed for research rather than industrial application.

This situation was resolved through the creation of a freely available, purely functional, lazy language called Haskell intended for use in research, education, and industry. Over the course of the 1990s, implementations of the Haskell language matured and Haskell eventually displaced Miranda in both education and research. Miranda continues to be used and taught in some places, but the niche it once filled is now occupied by Haskell.

While Haskell was intended to standardize the state of the art in lazy functional languages, it did end up introducing new ideas. Type classes were developed for the first version of Haskell. A type class can be looked at as a named description of the functions that an instance of the type class must support and the types of those functions. Types that are declared to be instances of a specific type class then must provide implementations of the type class's functions. In a surprising parallel to object-oriented programming, those functions thus become overloaded in a way that is resolved through a hierarchy of types. (Object-oriented programming's overloaded methods are resolved on the basis of the object's identity, an important distinction.) Type classes have been extended in various ways as Haskell evolved, and Haskell has become a playground for ``type hackery'' such as implementations of Peano arithmetic at the type level.

The other new idea that Haskell embraced was the use of monads. Monads entered Haskell some years after it was first standardized. They came by way of denotational semantics; practical experience with them in Haskell led to their extensive use to constrain side effects to well-defined regions of a program so that referential transparency is not destroyed. This led to a somewhat better solution to the problems of input--output that have long plagued functional programs (about which we will say more in the last part of this thesis).

Haskell has remained the state of the art in lazy functional languages. Its policy of allowing a published language definition to coexist with extensions of the language and various dialects has enabled further research to be carried out by extending or modifying Haskell. Extensions that are embraced by the community of Haskell users are subsequently standardized and included in the next revision of the standard. Use of Haskell outside research continues to grow, as does Haskell's influence in the world of programming languages.