\section{Middle End: Optimizing the IR}\label{background:compilers:middle}
% mostly just setting up the chapters in the next two parts; I've said a lot about this in other places, and the details come in those parts and don't even belong here
The middle end comes, as one might expect, between the front and back ends. Since it follows the front end, it has at hand the program in some form of \IR that encodes, not only the program, but useful information about the program. It precedes the back end, since its efforts can go some way towards easing the work of the back end. The purpose of the middle end is, given the program in some form, to work with that, possibly by manipulating it through various intermediate forms, to optimize the program. This is a rather vague aim with many possible interpretations, and this variety of interpretations is reflected in the variety of middle ends.

What does it mean, to optimize a program? In some sense, the entire compiler's work is an optimization of the program: it is given source code, a static, lifeless description of a program, and it produces a directly executable description of a program. This is the most significant improvement of all that a compiler makes. It is not surprising, then, that it took some time for the middle end to become a distinguished part of compiler architecture.

In general, though, when we speak of optimization without any clarification, we are talking about optimization for runtime speed. A program that is slow to respond is frustrating, and a program that is slower than necessary is wasteful of its users' time. In the past, when space was at a premium, it was acceptable to trade off speed for a smaller code size: a program you cannot fit in the available memory is no more executable than the original source code and is even more useless; you can at least read and learn something from the source code. Optimizations for code size are still important when it comes to limited memory situations like those encountered in embedded systems and in situations where the resultant program must be transmitted through a low-bandwidth channel. In addition to code size, space optimization can also attempt to minimize runtime usage of space. A software developer working on a program will want a completely different sort of optimization, one that enables the easiest debugging and most helpful profiling.

Speed, space, debugging, profiling\empause doubtless you could come up with more ways in which a program could be optimized. While these goals sometimes align, they also frequently compete. Different compilers will be better or worse at different kinds of optimization. Some will let you configure the optimizations they perform, though their inbuilt preference for one or another kind of optimization will still show itself in the diversity and quality of optimizations of the different kinds available. Sometimes, the available optimizations can be switched on and off in ways that would mean something to the casual user, like letting the user specify different levels of optimization or that the end product should support debugging, for example, the \spacedlowsmallcaps{GNU} compiler collection's (GCC's) family of optimization flags \code{-O}, \code{-O0}, \code{-O1}, $\dotsc$, \code{-O3} and its debugging family beginning with \code{-g}. Sometimes, the optimizations can only be switched on and off in their own cryptic language; some examples from GCC would be \code{-ftree-dominator-opts} and \code{-fgcse}.

We will be focusing on optimizations for speed, but even there, there is much room for variation. Optimization happens piecemeal: each optimization attempts to produce a specific sort of improvement. Some improvements can hinder others. Some complement each other. Often, the interaction of two optimizations cannot be predicted, since the specifics of their interaction will depend on the target architecture and the function being compiled. When you consider that a whole host of optimizations is going to be performed, some of them multiple times, it becomes clear that the question of which optimizations should be performed when is not a trivial problem.\label{background:compilers:middle-end:phase-ordering}

Optimizations are particular to their purpose and the type of program representation they work with. We discuss optimizations for imperative languages in \partandnameref{Chapter}{imperative:optimizing} and the optimizations used in compilers for two different functional languages in [sections to be written].%
%TODO: Update forward references to functional optimizations.