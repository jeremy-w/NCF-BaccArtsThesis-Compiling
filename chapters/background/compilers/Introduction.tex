A \vocab{compiler} is a translator. As in translation, there is a source language and a target language, and it is the translator's job to analyze the source text and produce ``equivalent'' text in the target language. When translating human languages, the equivalency of the original and a translation is only rough because there are so many factors on which to evaluate equivalency. When it comes to programming languages, however, we are not interested in the niceties of meter or alliteration, nor do we care about any subtleties of connotation: we want to map a computation expressed in one language to a computation expressed in another such that both produce identical outputs when given identical inputs.

Beyond that requirement, everything else about the computation is fair game for alteration. Since the source language is often unaware of the peculiarities of the target language, many of the details of how exactly the computation should be carried out are unspecified and open to interpretation: $5 \times 4$ can be calculated by straightforward multiplication of 5 and 4, but if $5 \times 2$ is already known, we need only multiply that quantity by 2, and since these multiplications happen to be powers of 2, we could instead employ bit shifts in place of multiplication, especially as a bit shift is likely to take less time than multiplication. Even if the source language is also the target language, the original source code might still be improved by careful translation without altering its behavior in the high-level sense of input-output mapping discussed above.

Alterations that will preserve observable behavior are called \vocab{safe}: correspondingly, alterations that might not are called \vocab{unsafe}. A compiler will never voluntarily perform unsafe alterations, though some allow the human user to instruct them to do so, as might at times seem desirable for runtime checks that serve only to catch errors that slipped past the programmer or when the human is able to determine that a transformation that appears to the compiler to be unsafe will, in fact, be safe in this case. The compiler must act conservatively: it can only consider safe those transformations that it can prove to be safe, and it must assume the worst where it cannot prove the behavior to be any better. The user need not make such assumptions.

You might be wondering whether, if compilers are translators, is there a similar programming language analogue for human language interpreters? There is, and they are even called \vocab{interpreters}. They perform on-the-fly interpretation: rather than translating the code for future execution, they directly execute it. They are not able to perform the extensive analysis of the whole program that compilers perform. It is, in fact, this degree of analysis that particularly distinguishes a compiler, though translation for the future rather than for the present is also frequently a characteristic. This latter characteristic, however, is less apparent in more recent developments such as \vocab{just-in-time compilation}, which might be coupled with an interpreter as in the Java Hotspot virtual machine. Our subject is neither interpreters nor just-in-time compilation, however, so this concludes our first and last words on the two subjects.

A compiler is a translator: it analyzes the source code and produces equivalent target code. This suggests a decomposition of the compiler into two parts, one performing analysis and the other generating target code. The analysis part is commonly called the \vocab{front end}, while the code generation part is called the \vocab{back end}. From our discussion of alterations and the relative speeds of multiplication versus bit shifts, you might also infer that the compiler also attempts, following its analysis, to improve the code in some fashion. This \vocab{optimization} is at times folded into the front and back ends, but as the number of optimizations employed rises and the complexity of performing them alongside the work of the front and back ends increases, it becomes wise to dedicate part of the compiler to optimization alone. Optimization can only be performed following analysis: we cannot improve what we do not understand. At the same time, we should like to generate optimized code as directly as possible. This suggests placing the optimizer between the front and back ends. Due to this common decomposition of concerns and arrangement of the flow of control between the parts, the part concerned with discovering and performing optimizations is sometimes wryly referred to as the \vocab{middle end} of the compiler.

