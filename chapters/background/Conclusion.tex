\myChapter{Conclusion}\label{background:conclusion}
This part provided background information essential to understanding the remainder of this work.
\begin{itemize}
\item In \partandnameref{Chapter}{background:beginnings}, we introduced the basic ideas of \lambdacalc and \TMs. These provide the fundamental models of computation for the functional and imperative paradigms, respectively. This connection will be made clearer in the following parts.

\item In \partandnameref{Chapter}{background:computers}, we used Turing machines as a bridge to modern computers. Succeeding sections described the three major parts of a computer: processor, memory, and input-output. Roughly, the processor is what lets a computer compute, memory provides storage, and input-output is what makes computers useful by allowing them to affect and interact with the world. We stressed the variety of processor architectures while giving some taste of that variety. We explained the existence of a memory hierarchy as well as the obstacle it presents to execution speed. We gave a rough sketch of how input-output is implemented in computers. We did not have much to say beyond this, since many of the details of input-output are more pertinent to programming languages themselves rather than their compilers.

\item In \partandnameref{Chapter}{background:compilers}, we surveyed compiler architecture and design. We introduced the three-part structure of a compiler and discussed each part. Along the way, we sketched the theory that lies at the basis of each part and how it is used in practice. We also briefly surveyed \IRs and their importance to the compiler. Lastly, we broached the chicken-and-egg issue of developing a compiler for a new programming language, implementing a compiler in its own source language, and similar logistical problems of compiler construction. The important point is that compilers neither develop in a vacuum nor spring fully-formed from the pregnant void, but evolve gradually, though this evolution may involve the seemingly contradictory device of the compiler effectively ``pulling itself up by its own bootstraps.''
\end{itemize}

\section{Bibliographic Notes}\label{background:conclusion:bibliographicnotes}
Later sections of this thesis treat \lambdacalc in more detail. %TODO: Convert to forward reference.
\citet{Hopcroft:Introduction:2007} is a standard textbook covering languages and \TMs and touching on computational complexity. Its emphasis is on the abstract machines and the languages themselves as opposed to scanning and parsing. The classic reference for compiler design is DRAGON, known affectionately as ``the dragon book'' for its cover art. (The color of the dragon is sometimes used to give the edition.) Many more recent texts still refer the reader to it for its detailed information on scanning and parsing, which is dealt with more cursorily in more modern texts to allow more discussion of optimization. A new edition was released in 2006 with some new content, but it is unclear to me at this time to what extent some of the older content\empause for example, the presentation of LALR parser generators as the culmination of LR parser generators, something that was no longer true even when the older 1986 edition was released\footnote{See, for example, PAGER and THE LIKE.}\empause has been updated.
%FIXME: This is a pathetic excuse. You need to get your hands on a copy of the new dragon.

A good, modern, introductory textbook on compiler design is \cite{Cooper:Engineering:2004}. CITE-ME-MUCHNICK picks up where a course using that book would leave off by giving more advanced information on the basic content and covering optimization and analysis in great detail. BLAH discusses the problem of optimization phase ordering.

Textbooks on compilers often seem to give the impression that scanning and parsing are a solved problems and the world has moved on. While that might be the case for scanning, parsing is still an active area of research. The Purdue Compiler Collection bucked the trend of providing LR-style parser generators in favor of developing an LL parser generator, now called ANTLR, for EXPANSION.\footnote{I am not yet sure whether the textual resemblance to anti-LR is simply a coincidence or not.} A better reference than DRAGON for parsing is THAT ONE PARSING BOOK. Other areas of research are implementing practical full LR parsers (see Menhir for an example) and GLR parsers (for example, Elkhound), as well as addressing problems of development of domain-specific languages and composable grammars; see, for example, BLAH's work.
%loop-scheduling
%optimization phase ordering
%CRIT-FIXME: Fix up the citations here! Need to load in a few more and maybe rewrite to match the citations I do have, like for opt phase ordering.